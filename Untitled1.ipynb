{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYU9Yp4WLoowwbqEufNa+B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raqcrisb/Meu_Projeto_Alura/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando o SDK do Google"
      ],
      "metadata": {
        "id": "TOcS7teXeEJJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FHlBnH1ASUK9"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LD8nDaYbeCwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY=\"\"\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "a4m67dBPfFwo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listar os modelos disponíveis"
      ],
      "metadata": {
        "id": "oIzbd_kZffgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "PjY010QZfb6P",
        "outputId": "da930ab1-4f3e-4030-d160-99c5954afdc1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config_lista = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.5,\n",
        "}"
      ],
      "metadata": {
        "id": "46lSzM_VjeZL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings_lista = {\n",
        "   \"harassment\": \"block_none\",\n",
        "   \"hate\": \"block_none\",\n",
        "   \"sexual\": \"block_none\",\n",
        "   \"dangerous\": \"block_none\",\n",
        "}"
      ],
      "metadata": {
        "id": "VRQILMDZlbXV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializando o modelo"
      ],
      "metadata": {
        "id": "2uE1mO5gnjmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\",\n",
        "                              generation_config=generation_config_lista,\n",
        "                              safety_settings=safety_settings_lista)"
      ],
      "metadata": {
        "id": "8Iabt6j9nnSP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criar um response"
      ],
      "metadata": {
        "id": "Zqw6r42EpcPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Vamos aprender conteúdo sobre IA. Me dê sugestões.\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "g3CKd-KBo2_w",
        "outputId": "77380ad6-d2aa-4e09-d06d-7c380e73bb34"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Conceitos Fundamentais:**\n",
            "\n",
            "* O que é Inteligência Artificial (IA)?\n",
            "* Tipos de IA: Aprendizado de Máquina, Aprendizado Profundo, Processamento de Linguagem Natural\n",
            "* Algoritmos de IA comuns: Regressão, Classificação, Agrupamento\n",
            "\n",
            "**Aprendizado de Máquina:**\n",
            "\n",
            "* Conceitos de Aprendizado Supervisionado, Não Supervisionado e por Reforço\n",
            "* Modelos de Aprendizado de Máquina: Árvores de Decisão, Regressão Linear, Redes Neurais\n",
            "* Avaliação de Modelos de Aprendizado de Máquina: Métricas, Curvas ROC\n",
            "\n",
            "**Aprendizado Profundo:**\n",
            "\n",
            "* Conceitos de Redes Neurais: Camadas, Funções de Ativação, Backpropagation\n",
            "* Tipos de Redes Neurais: Redes Neurais Convolucionais (CNNs), Redes Neurais Recorrentes (RNNs)\n",
            "* Aplicações de Aprendizado Profundo: Visão Computacional, Processamento de Linguagem Natural\n",
            "\n",
            "**Processamento de Linguagem Natural (PNL):**\n",
            "\n",
            "* Conceitos de PNL: Tokenização, Stemming, Lematização\n",
            "* Modelos de PNL: Modelos de Linguagem, Análise de Sentimento\n",
            "* Aplicações de PNL: Resumo Automático, Tradução Automática\n",
            "\n",
            "**Aplicações da IA:**\n",
            "\n",
            "* IA na Saúde: Diagnóstico, Tratamento, Descoberta de Medicamentos\n",
            "* IA nas Finanças: Detecção de Fraude, Análise de Mercado\n",
            "* IA na Indústria: Automação, Otimização de Processos\n",
            "* IA em Veículos Autônomos: Percepção, Controle, Navegação\n",
            "\n",
            "**Ética e Implicações Sociais da IA:**\n",
            "\n",
            "* Viés na IA\n",
            "* Privacidade e Segurança\n",
            "* Impacto no Emprego e na Sociedade\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "Go3yvm56qtUe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt= input(\"Eperando prompt: \")\n",
        "while prompt != \"fim\":\n",
        "  response = chat.send_message(prompt)\n",
        "  print(\"Resposta: \",response.text, \"\\n\")\n",
        "  prompt= input(\"Eperando prompt: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "Hh4zTrIushWc",
        "outputId": "828b11ec-b76f-423d-93ef-ad02a583af87"
      },
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eperando prompt: Qual é a capital do Japão?\n",
            "Resposta:  Tóquio \n",
            "\n",
            "Eperando prompt: Qual é a língua deste país ?\n",
            "Resposta:  Japonês \n",
            "\n",
            "Eperando prompt: fim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "# Imprimindo o histórico\n",
        "for message in chat.history:\n",
        "    display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))\n",
        "    print('___________________')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "2KdObDSyyzcY",
        "outputId": "3dea462e-f6e5-4244-b36f-49659ccf5ebe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: Qual é a capital do Japão?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "___________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: Tóquio"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "___________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: Qual é a língua deste país ?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "___________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: Japonês"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "___________________\n"
          ]
        }
      ]
    }
  ]
}
